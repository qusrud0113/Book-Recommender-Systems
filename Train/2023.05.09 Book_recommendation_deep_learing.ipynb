{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a0ed56d",
   "metadata": {},
   "source": [
    "# https://github.com/rixwew/pytorch-fm/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a395cdc4-d9d6-481b-9fae-703eb2ad49b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0f4d30-4f8f-4d90-8065-4a3c633a2898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(113) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a15ff4-f3ac-4741-9a24-5986866bca42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv( 'test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf91089-9a9c-43d7-92d4-bb47be87c66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_lb = pd.read_csv('train_lb.csv')\n",
    "test_lb = pd.read_csv('test_lb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12c91fd-df52-4074-a8c9-abf8f1ae4673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_lb.drop(columns = ['Unnamed: 0','ID', 'Book-Rating', 'Age', 'Year-Of-Publication', 'User_count', 'Rating_count', 'Author_count'])\n",
    "y_train = train_lb['Book-Rating']\n",
    "x_test = test_lb.drop(columns = ['Unnamed: 0','ID', 'Age', 'Year-Of-Publication', 'User_count', 'Rating_count', 'Author_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57092e35-dcfe-4a43-b2cd-393578aa4475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchfm in ./miniconda3/envs/rapids-23.04/lib/python3.10/site-packages (0.7.0)\n",
      "Collecting lmdb\n",
      "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lmdb\n",
      "Successfully installed lmdb-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchfm\n",
    "!pip install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b71d643-8a21-47f3-be82-d0b03b86e54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchfm.dataset.avazu import AvazuDataset\n",
    "from torchfm.dataset.criteo import CriteoDataset\n",
    "from torchfm.dataset.movielens import MovieLens1MDataset, MovieLens20MDataset\n",
    "from torchfm.model.afi import AutomaticFeatureInteractionModel\n",
    "from torchfm.model.afm import AttentionalFactorizationMachineModel\n",
    "from torchfm.model.dcn import DeepCrossNetworkModel\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from torchfm.model.ffm import FieldAwareFactorizationMachineModel\n",
    "from torchfm.model.fm import FactorizationMachineModel\n",
    "from torchfm.model.fnfm import FieldAwareNeuralFactorizationMachineModel\n",
    "from torchfm.model.fnn import FactorizationSupportedNeuralNetworkModel\n",
    "#from torchfm.model.hofm import HighOrderFactorizationMachineModel\n",
    "from torchfm.model.lr import LogisticRegressionModel\n",
    "from torchfm.model.ncf import NeuralCollaborativeFiltering\n",
    "from torchfm.model.nfm import NeuralFactorizationMachineModel\n",
    "from torchfm.model.pnn import ProductNeuralNetworkModel\n",
    "from torchfm.model.wd import WideAndDeepModel\n",
    "from torchfm.model.xdfm import ExtremeDeepFactorizationMachineModel\n",
    "from torchfm.model.afn import AdaptiveFactorizationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8402ee88-9817-4e52-a8b8-31c373f6ece6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83256 217829  92635  15505     12     11  13820   1810    348]\n"
     ]
    }
   ],
   "source": [
    "features = X_train.columns\n",
    "idx = {feature:None for feature in features}\n",
    "for feature in features :\n",
    "    feature2idx = {v:k for k,v in enumerate(X_train[feature].unique())}\n",
    "    idx[feature] = len(feature2idx)\n",
    "    X_train[feature] = X_train[feature].map(feature2idx)\n",
    "field_dims = np.array(list(idx.values()), dtype=np.uint32)\n",
    "print(field_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1dd94f2-d810-4850-b7d4-67fb6851e6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(name, dataset):\n",
    "    \"\"\"\n",
    "    Hyperparameters are empirically determined, not opitmized.\n",
    "    \"\"\"\n",
    "    if name == 'lr':\n",
    "        return LogisticRegressionModel(field_dims)\n",
    "    elif name == 'fm':\n",
    "        return FactorizationMachineModel(field_dims, embed_dim=16)\n",
    "    elif name == 'hofm':\n",
    "        return HighOrderFactorizationMachineModel(field_dims, order=3, embed_dim=16)\n",
    "    elif name == 'ffm':\n",
    "        return FieldAwareFactorizationMachineModel(field_dims, embed_dim=4)\n",
    "    elif name == 'fnn':\n",
    "        return FactorizationSupportedNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'wd':\n",
    "        return WideAndDeepModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'ipnn':\n",
    "        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method='inner', dropout=0.2)\n",
    "    elif name == 'opnn':\n",
    "        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method='outer', dropout=0.2)\n",
    "    elif name == 'dcn':\n",
    "        return DeepCrossNetworkModel(field_dims, embed_dim=16, num_layers=3, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'nfm':\n",
    "        return NeuralFactorizationMachineModel(field_dims, embed_dim=64, mlp_dims=(64,), dropouts=(0.2, 0.2))\n",
    "    elif name == 'ncf':\n",
    "        # only supports MovieLens dataset because for other datasets user/item colums are indistinguishable\n",
    "        assert isinstance(dataset, MovieLens20MDataset) or isinstance(dataset, MovieLens1MDataset)\n",
    "        return NeuralCollaborativeFiltering(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2,\n",
    "                                            user_field_idx=dataset.user_field_idx,\n",
    "                                            item_field_idx=dataset.item_field_idx)\n",
    "    elif name == 'fnfm':\n",
    "        return FieldAwareNeuralFactorizationMachineModel(field_dims, embed_dim=4, mlp_dims=(64,), dropouts=(0.2, 0.2))\n",
    "    elif name == 'dfm':\n",
    "        return DeepFactorizationMachineModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'xdfm':\n",
    "        return ExtremeDeepFactorizationMachineModel(\n",
    "            field_dims, embed_dim=16, cross_layer_sizes=(16, 16), split_half=False, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'afm':\n",
    "        return AttentionalFactorizationMachineModel(field_dims, embed_dim=16, attn_size=16, dropouts=(0.2, 0.2))\n",
    "    elif name == 'afi':\n",
    "        return AutomaticFeatureInteractionModel(\n",
    "             field_dims, embed_dim=16, atten_embed_dim=64, num_heads=2, num_layers=3, mlp_dims=(400, 400), dropouts=(0, 0, 0))\n",
    "    elif name == 'afn':\n",
    "        print(\"Model:AFN\")\n",
    "        return AdaptiveFactorizationNetwork(\n",
    "            field_dims, embed_dim=16, LNN_dim=1500, mlp_dims=(400, 400, 400), dropouts=(0, 0, 0))\n",
    "    else:\n",
    "        raise ValueError('unknown model name: ' + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcb8db7a-fe0c-4902-9d01-420e16076e90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopper(object):\n",
    "\n",
    "    def __init__(self, num_trials, save_path):\n",
    "        self.num_trials = num_trials\n",
    "        self.trial_counter = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def is_continuable(self, model, accuracy):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            self.trial_counter = 0\n",
    "            torch.save(model, self.save_path)\n",
    "            return True\n",
    "        elif self.trial_counter + 1 < self.num_trials:\n",
    "            self.trial_counter += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b9daef7-fc17-401c-b29b-e247f28e82bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.eps = 1e-6\n",
    "    def forward(self, x, y):\n",
    "        criterion = MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y)+self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b84e20e-1a33-4b90-8974-f3b5fd7a2443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, criterion, device, log_interval=100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0, position=0, leave=True)\n",
    "    for i, (fields, target) in enumerate(tk0):\n",
    "        fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            tk0.set_postfix(loss=total_loss / log_interval)\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2926cb87-2697-4b6d-a978-aae0e2dd0985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in (tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0, position=0, leave=True)):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            loss = RMSELoss(target, y)\n",
    "            total_loss += loss\n",
    "    return (total_loss/len(data_loader)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9a0f9f9e-3a62-4999-9ba2-9a2fa1ebfe07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "weight_decay=0\n",
    "epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c5db31dd-0b02-4890-b790-59bea78f9655",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87139"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8b8904ef-f954-48fd-af76-a93864924136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 2724/2724 [00:24<00:00, 113.28it/s, loss=4.25]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 341/341 [00:00<00:00, 640.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: RMSE: 4.235100746154785\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 2724/2724 [00:23<00:00, 114.89it/s, loss=4.22]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 341/341 [00:00<00:00, 645.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 validation: RMSE: 4.234694480895996\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|████████████████████▋                                               | 831/2724 [00:07<00:16, 115.25it/s, loss=4.25]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     RMSE \u001b[38;5;241m=\u001b[39m test(model, valid_data_loader, device)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation: RMSE:\u001b[39m\u001b[38;5;124m'\u001b[39m, RMSE)\n",
      "Cell \u001b[0;32mIn[89], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data_loader, criterion, device, log_interval)\u001b[0m\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 12\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m     tk0\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mtotal_loss \u001b[38;5;241m/\u001b[39m log_interval)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = torch.device(device)\n",
    "dataset = TensorDataset(torch.LongTensor(X_train.to_numpy()),\n",
    "                        torch.LongTensor(y_train.to_numpy()))\n",
    "train_length = int(len(dataset) * 0.8)\n",
    "valid_length = int(len(dataset) * 0.1)\n",
    "\n",
    "test_length = len(dataset) - train_length - valid_length\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_length, valid_length, test_length])\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "criterion = RMSELoss\n",
    "model = get_model('nfm', dataset).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "early_stopper = EarlyStopper(num_trials=2, save_path='nfm.pt')\n",
    "for epoch_i in range(epoch):\n",
    "    print(f\"Epoch {epoch_i+1}\")\n",
    "    train(model, optimizer, train_data_loader, criterion, device)\n",
    "    RMSE = test(model, valid_data_loader, device)\n",
    "    print('epoch:', epoch_i, 'validation: RMSE:', RMSE)\n",
    "    if not early_stopper.is_continuable(model, RMSE):\n",
    "        print(f'validation: best RMSE: {early_stopper.best_accuracy}')\n",
    "        break\n",
    "RMSE = test(model, test_data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3cb2e-8529-44ec-b248-154e1979ed28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
