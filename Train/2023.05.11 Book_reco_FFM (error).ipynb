{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2d2e0f-6d93-4275-9286-f32baa31e6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641656dc-20d8-46d8-bd3f-9c6cb6b896bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64c29c8-122b-48d3-a2f2-6599a9d8687d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(113) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fbd9ed-5ade-49de-931a-d346cd2d2c42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv( 'test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d64ae-8090-468d-9f5a-154373282403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def columns_create():    \n",
    "    global train_lb, test_lb\n",
    "    # User-ID기준 Rating count & check\n",
    "    count_columns = []\n",
    "    check_columns = []\n",
    "    for i in range(11):\n",
    "        train_lb[f\"count_{i}\"] = train_lb[train_lb['Book-Rating'] == i].groupby(['User-ID'])['Book-Rating'].transform('count')\n",
    "        train_lb[f\"count_{i}\"] = train_lb[f\"count_{i}\"].fillna(0)\n",
    "    \n",
    "        train_lb[f\"check_{i}\"] = np.where(train_lb[f\"count_{i}\"] > 0, 1, 0)\n",
    "        train_lb = train_lb.drop(columns = [f\"count_{i}\"]) \n",
    "        #count_columns.append(f\"count_{i}\")\n",
    "        check_columns.append(f\"check_{i}\")   \n",
    "    create_columns = check_columns# count_columns + check_columns\n",
    "    for i in range(11):\n",
    "        #train_lb[f\"count_{i}\"] = train_lb.groupby(['User-ID'])[f\"count_{i}\"].transform('max')\n",
    "        train_lb[f\"check_{i}\"] = train_lb.groupby(['User-ID'])[f\"check_{i}\"].transform('max')   \n",
    "    ct_ck_set = train_lb[['User-ID'] + create_columns].drop_duplicates()\n",
    "    test_lb = pd.merge(test_lb, ct_ck_set, on = 'User-ID', how = 'left')\n",
    "    test_lb[create_columns] = test_lb[create_columns].fillna(0)    \n",
    "    return check_columns, train_lb, test_lb #count_columns, \n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['Location'] = [re.sub(r'[^0-9a-zA-Z:,]',  ' ',str(i)) for i in df['Location']]\n",
    "    \n",
    "    df['City'] = [(i.split(',')[0]).lstrip().lower() for i in df['Location']]\n",
    "    df['State'] = [(i.split(',')[1]).lstrip().lower() for i in df['Location']]\n",
    "    df['Country'] = [(i.split(',')[2]).lstrip().lower() for i in df['Location']]\n",
    "\n",
    "    labels = ['0-3','3-6','6-8','8-12','12-18','18-25','25-34','35-44','45-54','55-64','65-74','75+']\n",
    "    bins = [0, 3, 6, 8, 12, 18, 25, 34, 44, 54, 64, 74, 250]\n",
    "    \n",
    "    # Age 이상치 처리\n",
    "    df['Age'] = df['Age'].apply(lambda x: 3 if x<3 else x)\n",
    "    df['Age'] = df['Age'].apply(lambda x: 100 if x>100 else x)\n",
    "\n",
    "    #df.loc[(df['Age'] > 90) | (df['Age'] < 3), 'Age'] = np.nan\n",
    "    \n",
    "    # 평균값으로 대체\n",
    "    #df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Age'] = df['Age'].astype(np.int32)\n",
    "\n",
    "    \n",
    "    df['Age_gb'] = pd.cut(df.Age, bins, labels = labels,include_lowest = True)\n",
    "    \n",
    "    # 출판년도 그룹화\n",
    "    # 만약 출판연도가 null이 있다면 정보없음(-1)로 채움\n",
    "    #df['Year-Of-Publication'] = df['Year-Of-Publication'].fillna(-1)\n",
    "    #labels = ['Unknown', '-1900', '1900-1950', '1950-1960', '1960-1970', '1970-1980', '1980-1990', '1990-2000', '2000-2010', '2010-2020', '2020-']\n",
    "    #bins = [-1, 0, 1900, 1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020, 3000]\n",
    "    #df['Pub_gb'] = pd.cut(df['Year-Of-Publication'], bins, labels = labels,include_lowest = True)    \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3778e-3687-4baf-8d0e-8d8e532cacbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re \n",
    "def preprocessing_data(df):\n",
    "    \n",
    "    # preprocessing Location\n",
    "    # NaN, N/A, etc.. Change 'unknown'\n",
    "    # Only using Train Data\t#\n",
    "    \n",
    "    # 최빈값을 사용하기 위해 새로운 데이터 프레임 생성(pd.Series.mode를 이용하면 같은 count수의 값을 list로 묶어서 정확하지 않음)\n",
    "    new_state = train_lb.groupby(['City'])['State'].value_counts().to_frame().rename(columns = {'State' : 'count'}).reset_index()\n",
    "    new_state = new_state[(~new_state['City'].isna())&(~new_state['State'].isna())&(new_state['count']!=1)]\n",
    "    new_state = new_state.sort_values(by=['City', 'count'], ascending=[True, False]).drop_duplicates(subset='City', keep='first')\n",
    "    new_state = new_state.rename(columns = {'State' : 'N_State'}) \n",
    "    new_state = new_state.drop(columns = ['count'])\n",
    "    \n",
    "    new_country = train_lb.groupby(['State'])['Country'].value_counts().to_frame().rename(columns = {'Country' : 'count'}).reset_index()\n",
    "    new_country = new_country[(~new_country['State'].isna())&(~new_country['Country'].isna())&(new_country['count']!=1)]\n",
    "    new_country = new_country.sort_values(by=['State', 'count'], ascending=[True, False]).drop_duplicates(subset='State', keep='first')\n",
    "    new_country = new_country.rename(columns = {'Country' : 'N_Country'}) \n",
    "    new_country = new_country.drop(columns = ['count'])\n",
    "    \n",
    "    df = pd.merge(df, new_country, on = 'State', how = 'left')\n",
    "    df = pd.merge(df, new_state, on = 'City', how = 'left')\n",
    "    \n",
    "    df['Country'] = np.where((df['Country'] == '')|(df['Country'].astype(str) == 'nan'), df['N_Country'], df['Country'])\n",
    "    df['State'] = np.where((df['State'] == '')|(df['State'].astype(str) == 'nan'), df['N_State'], df['State'])\n",
    "    df[['Country', 'State', 'City']] = df[['Country', 'State', 'City']].fillna(value= 'Unknown')\n",
    "    df = df.drop(columns = ['N_Country', 'N_State'])\n",
    "\n",
    "    # train user list\n",
    "    # 리뷰 빈도가 단 한 번이거나, train에서 나오지 않은 유저는 'New_user'로 취급함.\n",
    "    df['User-count'] = df.groupby('User-ID')['User-ID'].transform('count')\n",
    "    user_list = train['User-ID'].to_numpy()\n",
    "    df['User-ID'] = np.where(np.logical_or(df['User-count'] == 1, ~df['User-ID'].isin(user_list)), 'New_user', df['User-ID'])\n",
    "        #df['User-count'] = np.log1p(df['User-count'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32129f41-b39b-4315-a174-c97ba8a3c66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n",
    "\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']#', 'Pub_gb']#', 'Language'] ', \n",
    "\n",
    "train_lb = train.__deepcopy__() \n",
    "test_lb = test.__deepcopy__()\n",
    "\n",
    "check_columns, train_lb, test_lb = columns_create()\n",
    "\n",
    "train_lb = feature_engineering(train_lb)\n",
    "test_lb = feature_engineering(test_lb)\n",
    "\n",
    "train_lb = preprocessing_data(train_lb)\n",
    "test_lb = preprocessing_data(test_lb)\n",
    "\n",
    "train_lb = train_lb.drop(columns = ['Book-ID', 'Location'])\n",
    "test_lb = test_lb.drop(columns = ['Book-ID', 'Location'])\n",
    "\n",
    "train_lb[FEATURE] = train_lb[FEATURE].astype(str) \n",
    "test_lb[FEATURE] = test_lb[FEATURE].astype(str)\n",
    "\n",
    "\n",
    "for i in FEATURE:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train_lb[i])\n",
    "    for label in np.unique(test_lb[i].dropna()):\n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    train_lb[i] = le.transform(train_lb[i])\n",
    "    test_lb[i] = le.transform(test_lb[i])\n",
    "    \n",
    "#for i in FEATURE:\n",
    "#    # train에는 없고, test에는 있는 원소는 -2 처리\n",
    "#    oe = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "#                         unknown_value=-2)\n",
    "#    oe=oe.fit(train_lb[i].to_numpy().reshape(-1, 1))\n",
    "#    train_lb[i] = oe.transform(train_lb[i].to_numpy().reshape(-1, 1))\n",
    "#    test_lb[i] = oe.transform(test_lb[i].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb76bfa-089c-4362-ba78-5a090c846f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_lb.to_csv('train_lb.csv')\n",
    "test_lb.to_csv('test_lb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3641bf9-5444-4567-a407-25d7d85cc1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_lb = pd.read_csv('train_lb.csv')\n",
    "test_lb = pd.read_csv('test_lb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d4f4fa-fabc-4572-9099-8286bfd0fa2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_lb.drop(columns = ['Unnamed: 0', 'ID', 'Book-Rating', 'Age', 'Year-Of-Publication', 'User-count'])\n",
    "y_train = train_lb['Book-Rating']\n",
    "x_test = test_lb.drop(columns = ['Unnamed: 0', 'ID', 'Age', 'Year-Of-Publication','User-count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "252de616-54fb-4365-85a2-8990af4347f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn import MSELoss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "class FeaturesLinear(torch.nn.Module) :\n",
    "    def __init__(self, field_dims) :\n",
    "        '''\n",
    "        Parameter\n",
    "            field_dims : List of field dimensions\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = sum(field_dims)\n",
    "        self.linear = nn.Linear(self.input_dim, 1, bias=True)\n",
    "        self.offsets = np.array((0, *np.cumsum(field_dims)[:-1]), dtype=np.int32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Parameter\n",
    "            x : Long tensor of size (batch_size, num_fields)\n",
    "        \n",
    "        Return\n",
    "            linear_term : Float tensor of size (batch_size)\n",
    "        '''\n",
    "        x = x + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        sparse_x = torch.zeros(x.size(0), self.input_dim, device=x.device).scatter_(1, x, 1.)\n",
    "        linear_term = self.linear(sparse_x)\n",
    "        return linear_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29ad94b-004d-4bed-8b91-e4ece4d476ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FieldAwareEmbedding(torch.nn.Module) :\n",
    "\n",
    "    def __init__(self, field_dims, embed_dim) :\n",
    "        '''\n",
    "        Parameter\n",
    "            field_dims : List of field dimensions\n",
    "            embed_dim : Factorization dimension for dense embedding\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_fields = len(field_dims)\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(feature_size, embed_dim) for feature_size in field_dims\n",
    "        ])\n",
    "        for embedding in self.embeddings:\n",
    "            torch.nn.init.xavier_uniform_(embedding.weight.data)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        '''\n",
    "        Parameter\n",
    "            x : Long tensor of size (batch_size, num_fields)\n",
    "        \n",
    "        Return\n",
    "            dense_x : Long tensor of size (batch_size, num_fields, embed_dim)\n",
    "        '''\n",
    "        dense_x = [self.embeddings[i](x[..., i]) for i in range(self.num_fields)]\n",
    "        dense_x = torch.stack(dense_x, dim=1)\n",
    "        return dense_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e972794c-aae0-4ab3-bc83-2c4b06199a15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FieldAwareFactorizationMachine(torch.nn.Module) :\n",
    "    def __init__(self, field_dims, embed_dim) :\n",
    "        '''\n",
    "        Parameter\n",
    "            field_dims : List of field dimensions\n",
    "            embed_dim : Factorization dimension for dense embedding\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_fields = len(field_dims)\n",
    "        self.embeddings = FieldAwareEmbedding(field_dims, embed_dim)\n",
    "        self.linear = FeaturesLinear(field_dims)\n",
    "        \n",
    "    def square(self, x):\n",
    "        return torch.pow(x,2)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        '''\n",
    "        Parameter\n",
    "            x : Long tensor of size (batch_size, num_fields)\n",
    "        \n",
    "        Return\n",
    "            y_ffm : Float tensor of size (batch_size)\n",
    "        '''\n",
    "        linear_term = self.linear(x)\n",
    "        \n",
    "        dense_x = self.embeddings(x)\n",
    "\n",
    "        square_of_sum = self.square(torch.sum(dense_x, dim=1))\n",
    "        sum_of_square = torch.sum(self.square(dense_x), dim=1)\n",
    "        pairwise_term = 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1)\n",
    "        \n",
    "        y_ffm = linear_term.squeeze(1) + pairwise_term\n",
    "\n",
    "        return y_ffm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a58fc88-2873-42a9-811e-9f3457deb1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_tr, X_valid, y_tr, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42,\n",
    "                                                      shuffle=True, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "277602ff-489a-4f33-baf0-fa3b554d3a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.LongTensor(X_tr.to_numpy()),\n",
    "                              torch.LongTensor(y_tr.to_numpy()))\n",
    "valid_dataset = TensorDataset(torch.LongTensor(X_valid.to_numpy()),\n",
    "                              torch.LongTensor(y_valid.to_numpy()))\n",
    "\n",
    "test_dataset = TensorDataset(torch.LongTensor(x_test.to_numpy()),\n",
    "                              torch.LongTensor(np.zeros(x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e44fe5-20eb-45c5-b32c-9c156903ce95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.eps = 1e-6\n",
    "    def forward(self, x, y):\n",
    "        criterion = MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y)+self.eps)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52fe6f0c-9ac5-4ac2-a4ab-41c4a53e2fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_train(model, dataloader, loss_fn, optimizer, device) :\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for features, targets in tqdm(dataloader) :\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(torch.float32).to(device)\n",
    "        \n",
    "        outputs = model(features)\n",
    "        loss = loss_fn(targets, outputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        \n",
    "    return (total_loss/len(dataloader)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5c86d8b-3562-43d8-846d-d3b4de433062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_eval(model, dataloader, loss_fn, device) :\n",
    "    with torch.no_grad() :\n",
    "        total_loss = 0\n",
    "        model.eval()\n",
    "        for features, targets in tqdm(dataloader) :\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(torch.float32).to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "            loss = loss_fn(targets, outputs)\n",
    "            total_loss += loss\n",
    "            \n",
    "    return (total_loss/len(dataloader)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967797ee-1501-4269-b5a8-e95fd5d7e5af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d62ba9a-9256-4e2a-b6b5-798e9f6fe119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "idx = {feature:None for feature in features}\n",
    "for feature in features :\n",
    "    feature2idx = {v:k for k,v in enumerate(X_train[feature].unique())}\n",
    "    idx[feature] = len(feature2idx)\n",
    "    X_train[feature] = X_train[feature].map(feature2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbda6baa-1463-4592-8496-0710e5ec8a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36989 217829  92635  15505      2      2      2      2      2      2\n",
      "      2      2      2      2      2  13741   1766    349     12]\n"
     ]
    }
   ],
   "source": [
    "field_dims = np.array(list(idx.values()), dtype=np.uint32)\n",
    "print(field_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1ce0484-1eae-4b8b-9657-858957ec74c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "embed_dim = 4\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9531b7d-bf3b-492d-8b88-a28361b6dc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffm_model = FieldAwareFactorizationMachine(field_dims, embed_dim=embed_dim)\n",
    "ffm_model.to(device)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "loss_fn = RMSELoss()\n",
    "optimizer = torch.optim.Adam(ffm_model.parameters(), lr=lr)\n",
    "\n",
    "best_loss = int(1e8)\n",
    "check_cnt = 0\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "    train_loss = model_train(ffm_model, train_loader, loss_fn, optimizer, device)\n",
    "    valid_loss = model_eval(ffm_model, valid_loader, loss_fn, device)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss : {train_loss:.2f}, Validation Loss : {valid_loss:.2f}\")\n",
    "    \n",
    "    if best_loss > valid_loss :\n",
    "        best_loss = valid_loss\n",
    "        torch.save(ffm_model.state_dict(), 'ffm_model.pt')\n",
    "        check_cnt = 0\n",
    "    else :\n",
    "        check_cnt += 1\n",
    "        if check_cnt == 5 :\n",
    "            print(\"Early Stopped\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cefffcc-0268-4cb5-9e8e-9f662cbd2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = FieldAwareFactorizationMachine(field_dims, embed_dim).to(device)\n",
    "best_model.load_state_dict(torch.load('ffm_model.pt'))\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "414cce48-c6da-4e15-850f-fa2481249f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39d68a41-d7d7-4ac9-9fcd-a9d68ae74b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_pred(model, dataloader, device) :\n",
    "    pred = []\n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        for features, targets in tqdm(dataloader) :\n",
    "            features = features.to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "            pred.append(outputs)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01559033-0df9-433e-8395-9b0c7cb1c354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/624 [00:00<?, ?it/s]../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [7,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "  0%|                                                                                           | 0/624 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pred\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m, in \u001b[0;36mmodel_pred\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m features, targets \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader) :\n\u001b[1;32m      6\u001b[0m         features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m         pred\u001b[38;5;241m.\u001b[39mappend(outputs)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mFieldAwareFactorizationMachine.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03mParameter\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    x : Long tensor of size (batch_size, num_fields)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    y_ffm : Float tensor of size (batch_size)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m linear_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[0;32m---> 26\u001b[0m dense_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m square_of_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msquare(torch\u001b[38;5;241m.\u001b[39msum(dense_x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     29\u001b[0m sum_of_square \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msquare(dense_x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36mFieldAwareEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x) :\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Parameter\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        x : Long tensor of size (batch_size, num_fields)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m        dense_x : Long tensor of size (batch_size, num_fields, embed_dim)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     dense_x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings[i](x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_fields)]\n\u001b[1;32m     26\u001b[0m     dense_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(dense_x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dense_x\n",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x) :\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Parameter\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        x : Long tensor of size (batch_size, num_fields)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m        dense_x : Long tensor of size (batch_size, num_fields, embed_dim)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     dense_x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_fields)]\n\u001b[1;32m     26\u001b[0m     dense_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(dense_x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dense_x\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "pred = model_pred(best_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7463140-55e9-4e12-9557-b7bc80ebe8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
