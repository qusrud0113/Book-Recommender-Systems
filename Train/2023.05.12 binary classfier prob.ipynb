{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e239a8fe-8b3d-4b6f-8a86-699a5d6d6964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba0ac1a-431d-4aad-9b50-2e9b313b5e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e661d7-37a8-4f49-83f2-1336b44faa88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(113) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc26c53d-af3e-46bb-a1d9-67ec4394fbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv( 'test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2aec257-43c0-443c-ad2a-374a3294f959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['Location'] = [re.sub(r'[^0-9a-zA-Z:,]',  ' ',str(i)) for i in df['Location']]\n",
    "    \n",
    "    df['City'] = [(i.split(',')[0]).lstrip().lower() for i in df['Location']]\n",
    "    df['State'] = [(i.split(',')[1]).lstrip().lower() for i in df['Location']]\n",
    "    df['Country'] = [(i.split(',')[2]).lstrip().lower() for i in df['Location']]\n",
    "\n",
    "    labels = ['0-3','3-6','6-8','8-12','12-18','18-25','25-34','35-44','45-54','55-64','65-74','75+']\n",
    "    bins = [0, 3, 6, 8, 12, 18, 25, 34, 44, 54, 64, 74, 250]\n",
    "    \n",
    "    # Age 이상치 처리\n",
    "    df['Age'] = df['Age'].apply(lambda x: 3 if x<3 else x)\n",
    "    df['Age'] = df['Age'].apply(lambda x: 100 if x>100 else x)\n",
    "\n",
    "    #df.loc[(df['Age'] > 90) | (df['Age'] < 3), 'Age'] = np.nan\n",
    "    \n",
    "    # 평균값으로 대체\n",
    "    #df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    #df['Age'] = df['Age'].astype(np.int32)\n",
    "\n",
    "    \n",
    "    df['Age_gb'] = pd.cut(df.Age, bins, labels = labels,include_lowest = True)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db71e71c-9939-41ea-887c-a9c7b7803449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re \n",
    "def preprocessing_data(df):\n",
    "    \n",
    "    # preprocessing Location\n",
    "    # NaN, N/A, etc.. Change 'unknown'\n",
    "    # Only using Train Data\t#\n",
    "    \n",
    "    # 최빈값을 사용하기 위해 새로운 데이터 프레임 생성(pd.Series.mode를 이용하면 같은 count수의 값을 list로 묶어서 정확하지 않음)\n",
    "    new_state = train_lb.groupby(['City'])['State'].value_counts().to_frame().rename(columns = {'State' : 'count'}).reset_index()\n",
    "    new_state = new_state[(~new_state['City'].isna())&(~new_state['State'].isna())&(new_state['count']!=1)]\n",
    "    new_state = new_state.sort_values(by=['City', 'count'], ascending=[True, False]).drop_duplicates(subset='City', keep='first')\n",
    "    new_state = new_state.rename(columns = {'State' : 'N_State'}) \n",
    "    new_state = new_state.drop(columns = ['count'])\n",
    "    \n",
    "    new_country = train_lb.groupby(['State'])['Country'].value_counts().to_frame().rename(columns = {'Country' : 'count'}).reset_index()\n",
    "    new_country = new_country[(~new_country['State'].isna())&(~new_country['Country'].isna())&(new_country['count']!=1)]\n",
    "    new_country = new_country.sort_values(by=['State', 'count'], ascending=[True, False]).drop_duplicates(subset='State', keep='first')\n",
    "    new_country = new_country.rename(columns = {'Country' : 'N_Country'}) \n",
    "    new_country = new_country.drop(columns = ['count'])\n",
    "    \n",
    "    df = pd.merge(df, new_country, on = 'State', how = 'left')\n",
    "    df = pd.merge(df, new_state, on = 'City', how = 'left')\n",
    "    \n",
    "    df['Country'] = np.where((df['Country'] == '')|(df['Country'].astype(str) == 'nan'), df['N_Country'], df['Country'])\n",
    "    df['State'] = np.where((df['State'] == '')|(df['State'].astype(str) == 'nan'), df['N_State'], df['State'])\n",
    "    \n",
    "    # 채워지지 않은 값은 Unknown 처리\n",
    "    df[['Country', 'State', 'City']] = df[['Country', 'State', 'City']].fillna(value= 'Unknown')\n",
    "    df = df.drop(columns = ['N_Country', 'N_State'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5401923f-93e7-405f-91f2-19e2d70131f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']#, 'Pub_gb']#, 'Language'] ', \n",
    "\n",
    "train_lb = train.__deepcopy__() \n",
    "test_lb = test.__deepcopy__()\n",
    "\n",
    "\n",
    "train_lb = feature_engineering(train_lb)\n",
    "test_lb = feature_engineering(test_lb)\n",
    "\n",
    "train_lb = preprocessing_data(train_lb)\n",
    "test_lb = preprocessing_data(test_lb)\n",
    "\n",
    "train_lb = train_lb.drop(columns = ['Book-ID', 'Location'])\n",
    "test_lb = test_lb.drop(columns = ['Book-ID', 'Location'])\n",
    "\n",
    "train_lb[FEATURE] = train_lb[FEATURE].astype(str) \n",
    "test_lb[FEATURE] = test_lb[FEATURE].astype(str)\n",
    "\n",
    "# 평점 binary 분류\n",
    "#zero_user = train[train['Book-Rating'] == 0][['User-ID', 'Book-Rating']].drop_duplicates()['User-ID']\n",
    "train_lb['Rating_gb'] = np.where(train_lb['Book-Rating'] == 0, 0, 1)\n",
    "\n",
    "for i in FEATURE:\n",
    "    # train에는 없고, test에는 있는 원소는 -2 처리\n",
    "    oe = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                         unknown_value=-2)\n",
    "    oe=oe.fit(train_lb[i].to_numpy().reshape(-1, 1))\n",
    "    train_lb[i] = oe.transform(train_lb[i].to_numpy().reshape(-1, 1))\n",
    "    test_lb[i] = oe.transform(test_lb[i].to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50c7573e-94ee-4d9f-bdb7-a973ba2ffccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_lb.drop(columns = ['ID' , 'Book-Rating', 'Rating_gb'])\n",
    "x_test = test_lb.drop(columns = ['ID'])\n",
    "y_train_cf = train_lb['Rating_gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2fe71a9-4700-4c95-950b-e0d7ac155e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>136251.0</td>\n",
       "      <td>77475.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>9093.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>103076.0</td>\n",
       "      <td>91647.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>10515.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>208319.0</td>\n",
       "      <td>90102.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>10515.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111765.0</td>\n",
       "      <td>83754.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>143993.0</td>\n",
       "      <td>54167.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>12609.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871388</th>\n",
       "      <td>83251.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>73499.0</td>\n",
       "      <td>52004.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>7728.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871389</th>\n",
       "      <td>83252.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>186183.0</td>\n",
       "      <td>16876.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>12055.0</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871390</th>\n",
       "      <td>83253.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>72770.0</td>\n",
       "      <td>36822.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>13698.0</td>\n",
       "      <td>9067.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871391</th>\n",
       "      <td>83254.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73851.0</td>\n",
       "      <td>87010.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>12989.0</td>\n",
       "      <td>7277.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871392</th>\n",
       "      <td>83255.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>164203.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871393 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID   Age  Book-Title  Book-Author  Year-Of-Publication  \\\n",
       "0           0.0  23.0    136251.0      77475.0               2001.0   \n",
       "1           0.0  23.0    103076.0      91647.0               1981.0   \n",
       "2           0.0  23.0    208319.0      90102.0               1981.0   \n",
       "3           0.0  23.0    111765.0      83754.0               1991.0   \n",
       "4           0.0  23.0    143993.0      54167.0               1989.0   \n",
       "...         ...   ...         ...          ...                  ...   \n",
       "871388  83251.0  34.0     73499.0      52004.0               1993.0   \n",
       "871389  83252.0  35.0    186183.0      16876.0               2002.0   \n",
       "871390  83253.0  45.0     72770.0      36822.0               2000.0   \n",
       "871391  83254.0  43.0     73851.0      87010.0               1996.0   \n",
       "871392  83255.0  35.0    164203.0       4221.0               1999.0   \n",
       "\n",
       "        Publisher     City   State  Country  Age_gb  \n",
       "0          9093.0  10487.0  1037.0     57.0     2.0  \n",
       "1         10515.0  10487.0  1037.0     57.0     2.0  \n",
       "2         10515.0  10487.0  1037.0     57.0     2.0  \n",
       "3          1166.0  10487.0  1037.0     57.0     2.0  \n",
       "4         12609.0  10487.0  1037.0     57.0     2.0  \n",
       "...           ...      ...     ...      ...     ...  \n",
       "871388     6162.0   7728.0   955.0    323.0     3.0  \n",
       "871389     6091.0  12055.0  1534.0    323.0     5.0  \n",
       "871390    13698.0   9067.0  1160.0     57.0     6.0  \n",
       "871391    12989.0   7277.0   955.0    323.0     5.0  \n",
       "871392     6037.0   2092.0  1560.0    146.0     5.0  \n",
       "\n",
       "[871393 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b37003-f589-412c-993e-1d8b4270fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1. binary classifier of 0 or other\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "k = 5 # a number of folds best is 20\n",
    "skfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=113)\n",
    "\n",
    "model_cf = CatBoostClassifier(loss_function='Logloss', iterations =3000)\n",
    "\n",
    "y_train_pred = 0\n",
    "y_test_pred = 0\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(skfold.split(X_train, y_train))):    \n",
    "    X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_train_fold[FEATURE] = X_train_fold[FEATURE].astype('int')\n",
    "    X_valid_fold[FEATURE] = X_valid_fold[FEATURE].astype('int')\n",
    "    \n",
    "    train_pool = Pool(data=X_train_fold, label=y_train_fold, cat_features=FEATURE)\n",
    "    valid_pool = Pool(data=X_valid_fold, label=y_valid_fold, cat_features=FEATURE)\n",
    "\n",
    "    \n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    fit_model = model_cf.fit(train_pool, \n",
    "                          eval_set=valid_pool,\n",
    "                          use_best_model=True,\n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose=50\n",
    "                          )\n",
    "    print( \"  N trees = \", model.tree_count_ )      \n",
    "  \n",
    "    x_test[FEATURE] = x_test[FEATURE].astype('int')\n",
    "    # Predict value Clipping\n",
    "    y_train_prob +=  fit_model.predict_proba(X_train[X_valid_fold.columns])\n",
    "    y_test_prob +=  fit_model.predict_proba(x_test[X_valid_fold.columns])\n",
    "y_train_prob /= k\n",
    "y_test_prob /= k  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a9bc4-fa22-4775-b89a-8e7a35c293fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['RT_prob'] = y_train_prob\n",
    "x_test['RT_prob'] = y_test_prob  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34aceaa-4cbb-4214-9474-88db970a6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_lb['Book-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1889b-fdaa-4e0a-b653-106059b5a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7, 7))\n",
    "clustermap = sns.clustermap(X_train.corr(), cmap = 'RdYlBu_r',vmin = -1, vmax = 1, annot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f9b0a-fa46-41f9-858e-3679bb89eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "model = CatBoostRegressor(random_seed = 113,\n",
    "                          l2_leaf_reg = 0.003426034644149707,\n",
    "                          max_bin = 358,\n",
    "                          subsample = 0.9974697184313627,\n",
    "                          learning_rate = 0.009464402227606937,\n",
    "                          max_depth = 11,\n",
    "                          min_data_in_leaf = 139,\n",
    "                          eval_metric = 'RMSE',\n",
    "                          iterations = 8694,\n",
    "                          task_type='GPU',\n",
    "                          bootstrap_type = 'Poisson',\n",
    "                          early_stopping_rounds = 100,\n",
    "                          verbose=500\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112a0a1-c925-4152-a311-ea9586180f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "k = 20 # a number of folds best is 20\n",
    "skfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=113)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score\n",
    "from catboost import Pool\n",
    "\n",
    "y_valid_pred = 0*y_train\n",
    "y_test_pred = 0\n",
    "\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']#, 'Rating_gb']# 'Pub_gb']\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(skfold.split(X_train, y_train))):    \n",
    "    X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_train_fold[FEATURE] = X_train_fold[FEATURE].astype('int')\n",
    "    X_valid_fold[FEATURE] = X_valid_fold[FEATURE].astype('int')\n",
    "    \n",
    "    train_pool = Pool(data=X_train_fold, label=y_train_fold, cat_features=FEATURE)\n",
    "    valid_pool = Pool(data=X_valid_fold, label=y_valid_fold, cat_features=FEATURE)\n",
    "\n",
    "    \n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    fit_model = model.fit(train_pool, \n",
    "                          eval_set=valid_pool,\n",
    "                          use_best_model=True\n",
    "                          )\n",
    "    print( \"  N trees = \", model.tree_count_ )\n",
    "        \n",
    "\n",
    "    def score_model(model,X_train, X_test, y_train, y_test,\n",
    "               show_plot=True):   \n",
    "        y_pred = np.clip(model.predict(X_test),0,10)\n",
    "        print(f\"Test score: {r2_score(y_test, y_pred)}\")\n",
    "        print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "        print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "        predictions_comparision = pd.DataFrame({'Actual': y_test.tolist(), 'Predicted': y_pred.tolist()}).sample(25)\n",
    "        if show_plot == True:\n",
    "            predictions_comparision.plot(kind=\"bar\", figsize=(12,8),title=\"Actual vs predicted values\")\n",
    "            print(predictions_comparision.sample(10))    \n",
    "    \n",
    "    \n",
    "        return {\n",
    "            \"test_score_r2\" : r2_score(y_test, y_pred),\n",
    "            \"test_score_mse\" : mean_squared_error(y_test, y_pred),\n",
    "            \"test_score_rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            }\n",
    "    score_model(fit_model, X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, show_plot=True)\n",
    "    \n",
    "    x_test[FEATURE] = x_test[FEATURE].astype('int')\n",
    "    # Predict value Clipping\n",
    "    y_test_pred +=  np.clip(fit_model.predict(x_test[X_valid_fold.columns]),0.0,10.0)\n",
    "    \n",
    "y_test_pred /= k  # Average test set predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef48dcb-c7a2-4e6d-93b0-7d60c8d9989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_importance_feature = np.argsort(model.feature_importances_)[:-31:-1]\n",
    "plt.barh(X_train.columns[cat_importance_feature], model.feature_importances_[cat_importance_feature])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b65b1-bd59-4f95-bdac-324cb42b9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['ID'] = test['ID']\n",
    "sub['Book-Rating'] = y_test_pred\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eda32e-6d8c-4f88-9174-ffe9219afc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(sub['Book-Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab828f-ebae-443d-a51a-4c44f48e3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submit_cat+20-folds+binary.csv', index=False,encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
