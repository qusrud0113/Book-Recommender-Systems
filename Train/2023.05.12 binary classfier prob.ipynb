{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e239a8fe-8b3d-4b6f-8a86-699a5d6d6964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba0ac1a-431d-4aad-9b50-2e9b313b5e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e661d7-37a8-4f49-83f2-1336b44faa88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(113) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc26c53d-af3e-46bb-a1d9-67ec4394fbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv( 'test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2aec257-43c0-443c-ad2a-374a3294f959",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['Location'] = [re.sub(r'[^0-9a-zA-Z:,]',  ' ',str(i)) for i in df['Location']]\n",
    "    \n",
    "    df['City'] = [(i.split(',')[0]).lstrip().lower() for i in df['Location']]\n",
    "    df['State'] = [(i.split(',')[1]).lstrip().lower() for i in df['Location']]\n",
    "    df['Country'] = [(i.split(',')[2]).lstrip().lower() for i in df['Location']]\n",
    "\n",
    "    labels = ['0-3','3-6','6-8','8-12','12-18','18-25','25-34','35-44','45-54','55-64','65-74','75+']\n",
    "    bins = [0, 3, 6, 8, 12, 18, 25, 34, 44, 54, 64, 74, 250]\n",
    "    \n",
    "    # Age 이상치 처리\n",
    "    df['Age'] = df['Age'].apply(lambda x: 3 if x<3 else x)\n",
    "    df['Age'] = df['Age'].apply(lambda x: 100 if x>100 else x)\n",
    "\n",
    "    #df.loc[(df['Age'] > 90) | (df['Age'] < 3), 'Age'] = np.nan\n",
    "    \n",
    "    # 평균값으로 대체\n",
    "    #df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    #df['Age'] = df['Age'].astype(np.int32)\n",
    "\n",
    "    \n",
    "    df['Age_gb'] = pd.cut(df.Age, bins, labels = labels,include_lowest = True)    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db71e71c-9939-41ea-887c-a9c7b7803449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re \n",
    "def preprocessing_data(df):\n",
    "    \n",
    "    # preprocessing Location\n",
    "    # NaN, N/A, etc.. Change 'unknown'\n",
    "    # Only using Train Data\t#\n",
    "    \n",
    "    # 최빈값을 사용하기 위해 새로운 데이터 프레임 생성(pd.Series.mode를 이용하면 같은 count수의 값을 list로 묶어서 정확하지 않음)\n",
    "    new_state = train_lb.groupby(['City'])['State'].value_counts().to_frame().rename(columns = {'State' : 'count'}).reset_index()\n",
    "    new_state = new_state[(~new_state['City'].isna())&(~new_state['State'].isna())&(new_state['count']!=1)]\n",
    "    new_state = new_state.sort_values(by=['City', 'count'], ascending=[True, False]).drop_duplicates(subset='City', keep='first')\n",
    "    new_state = new_state.rename(columns = {'State' : 'N_State'}) \n",
    "    new_state = new_state.drop(columns = ['count'])\n",
    "    \n",
    "    new_country = train_lb.groupby(['State'])['Country'].value_counts().to_frame().rename(columns = {'Country' : 'count'}).reset_index()\n",
    "    new_country = new_country[(~new_country['State'].isna())&(~new_country['Country'].isna())&(new_country['count']!=1)]\n",
    "    new_country = new_country.sort_values(by=['State', 'count'], ascending=[True, False]).drop_duplicates(subset='State', keep='first')\n",
    "    new_country = new_country.rename(columns = {'Country' : 'N_Country'}) \n",
    "    new_country = new_country.drop(columns = ['count'])\n",
    "    \n",
    "    df = pd.merge(df, new_country, on = 'State', how = 'left')\n",
    "    df = pd.merge(df, new_state, on = 'City', how = 'left')\n",
    "    \n",
    "    df['Country'] = np.where((df['Country'] == '')|(df['Country'].astype(str) == 'nan'), df['N_Country'], df['Country'])\n",
    "    df['State'] = np.where((df['State'] == '')|(df['State'].astype(str) == 'nan'), df['N_State'], df['State'])\n",
    "    \n",
    "    # 채워지지 않은 값은 Unknown 처리\n",
    "    df[['Country', 'State', 'City']] = df[['Country', 'State', 'City']].fillna(value= 'Unknown')\n",
    "    df = df.drop(columns = ['N_Country', 'N_State'])\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5401923f-93e7-405f-91f2-19e2d70131f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']#, 'Pub_gb']#, 'Language'] ', \n",
    "\n",
    "train_lb = train.__deepcopy__() \n",
    "test_lb = test.__deepcopy__()\n",
    "\n",
    "\n",
    "train_lb = feature_engineering(train_lb)\n",
    "test_lb = feature_engineering(test_lb)\n",
    "\n",
    "train_lb = preprocessing_data(train_lb)\n",
    "test_lb = preprocessing_data(test_lb)\n",
    "\n",
    "train_lb = train_lb.drop(columns = ['Book-ID', 'Location'])\n",
    "test_lb = test_lb.drop(columns = ['Book-ID', 'Location'])\n",
    "\n",
    "train_lb[FEATURE] = train_lb[FEATURE].astype(str) \n",
    "test_lb[FEATURE] = test_lb[FEATURE].astype(str)\n",
    "\n",
    "# 평점 binary 분류\n",
    "#zero_user = train[train['Book-Rating'] == 0][['User-ID', 'Book-Rating']].drop_duplicates()['User-ID']\n",
    "train_lb['Rating_gb'] = np.where(train_lb['Book-Rating'] == 0, 0, 1)\n",
    "\n",
    "for i in FEATURE:\n",
    "    # train에는 없고, test에는 있는 원소는 -2 처리\n",
    "    oe = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                         unknown_value=-2)\n",
    "    oe=oe.fit(train_lb[i].to_numpy().reshape(-1, 1))\n",
    "    train_lb[i] = oe.transform(train_lb[i].to_numpy().reshape(-1, 1))\n",
    "    test_lb[i] = oe.transform(test_lb[i].to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50c7573e-94ee-4d9f-bdb7-a973ba2ffccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train_lb.drop(columns = ['ID' , 'Book-Rating', 'Rating_gb'])\n",
    "x_test = test_lb.drop(columns = ['ID'])\n",
    "y_train_cf = train_lb['Rating_gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2fe71a9-4700-4c95-950b-e0d7ac155e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age_gb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>136251.0</td>\n",
       "      <td>77475.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>9093.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>103076.0</td>\n",
       "      <td>91647.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>10515.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>208319.0</td>\n",
       "      <td>90102.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>10515.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111765.0</td>\n",
       "      <td>83754.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1166.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>143993.0</td>\n",
       "      <td>54167.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>12609.0</td>\n",
       "      <td>10487.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871388</th>\n",
       "      <td>83251.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>73499.0</td>\n",
       "      <td>52004.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>6162.0</td>\n",
       "      <td>7728.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871389</th>\n",
       "      <td>83252.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>186183.0</td>\n",
       "      <td>16876.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>12055.0</td>\n",
       "      <td>1534.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871390</th>\n",
       "      <td>83253.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>72770.0</td>\n",
       "      <td>36822.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>13698.0</td>\n",
       "      <td>9067.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871391</th>\n",
       "      <td>83254.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>73851.0</td>\n",
       "      <td>87010.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>12989.0</td>\n",
       "      <td>7277.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871392</th>\n",
       "      <td>83255.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>164203.0</td>\n",
       "      <td>4221.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>2092.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>871393 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID   Age  Book-Title  Book-Author  Year-Of-Publication  \\\n",
       "0           0.0  23.0    136251.0      77475.0               2001.0   \n",
       "1           0.0  23.0    103076.0      91647.0               1981.0   \n",
       "2           0.0  23.0    208319.0      90102.0               1981.0   \n",
       "3           0.0  23.0    111765.0      83754.0               1991.0   \n",
       "4           0.0  23.0    143993.0      54167.0               1989.0   \n",
       "...         ...   ...         ...          ...                  ...   \n",
       "871388  83251.0  34.0     73499.0      52004.0               1993.0   \n",
       "871389  83252.0  35.0    186183.0      16876.0               2002.0   \n",
       "871390  83253.0  45.0     72770.0      36822.0               2000.0   \n",
       "871391  83254.0  43.0     73851.0      87010.0               1996.0   \n",
       "871392  83255.0  35.0    164203.0       4221.0               1999.0   \n",
       "\n",
       "        Publisher     City   State  Country  Age_gb  \n",
       "0          9093.0  10487.0  1037.0     57.0     2.0  \n",
       "1         10515.0  10487.0  1037.0     57.0     2.0  \n",
       "2         10515.0  10487.0  1037.0     57.0     2.0  \n",
       "3          1166.0  10487.0  1037.0     57.0     2.0  \n",
       "4         12609.0  10487.0  1037.0     57.0     2.0  \n",
       "...           ...      ...     ...      ...     ...  \n",
       "871388     6162.0   7728.0   955.0    323.0     3.0  \n",
       "871389     6091.0  12055.0  1534.0    323.0     5.0  \n",
       "871390    13698.0   9067.0  1160.0     57.0     6.0  \n",
       "871391    12989.0   7277.0   955.0    323.0     5.0  \n",
       "871392     6037.0   2092.0  1560.0    146.0     5.0  \n",
       "\n",
       "[871393 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4af4e4b-cbbb-4b0f-8679-e8598c725ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.099005\n",
      "0:\tlearn: 0.6585040\ttest: 0.6562433\tbest: 0.6562433 (0)\ttotal: 274ms\tremaining: 13m 41s\n",
      "50:\tlearn: 0.5160534\ttest: 0.4996818\tbest: 0.4996818 (50)\ttotal: 12.7s\tremaining: 12m 15s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m Pool(data\u001b[38;5;241m=\u001b[39mX_tt, label\u001b[38;5;241m=\u001b[39my_tt, cat_features\u001b[38;5;241m=\u001b[39mFEATURE)\n\u001b[1;32m     14\u001b[0m model_cf \u001b[38;5;241m=\u001b[39m CatBoostClassifier(loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, iterations \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel_cf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/catboost/core.py:5131\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5129\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5131\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5132\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5133\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/catboost/core.py:2357\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2353\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2356\u001b[0m     plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2366\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/catboost/core.py:1761\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1761\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4624\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4673\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model1. binary classifier of 0 or other\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']\n",
    "\n",
    "X_tr, X_tt, y_tr, y_tt = train_test_split(X_train, y_train_cf, test_size=0.2, shuffle=True, random_state=113)\n",
    "X_tr[FEATURE] = X_tr[FEATURE].astype('int')\n",
    "X_tt[FEATURE] = X_tt[FEATURE].astype('int')\n",
    "    \n",
    "train_data = Pool(data=X_tr, label=y_tr, cat_features=FEATURE)\n",
    "valid_data = Pool(data=X_tt, label=y_tt, cat_features=FEATURE)\n",
    "\n",
    "\n",
    "model_cf = CatBoostClassifier(loss_function='Logloss', iterations =3000)\n",
    "model_cf.fit(train_data, eval_set=valid_data, use_best_model=True, early_stopping_rounds=50, verbose=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a9bc4-fa22-4775-b89a-8e7a35c293fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['RT_prob'] = model_cf.predict_proba(X_train)\n",
    "x_test['RT_prob'] = model_cf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34aceaa-4cbb-4214-9474-88db970a6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_lb['Book-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1889b-fdaa-4e0a-b653-106059b5a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7, 7))\n",
    "clustermap = sns.clustermap(X_train.corr(), cmap = 'RdYlBu_r',vmin = -1, vmax = 1, annot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f9b0a-fa46-41f9-858e-3679bb89eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "model = CatBoostRegressor(random_seed = 113,\n",
    "                          l2_leaf_reg = 0.003426034644149707,\n",
    "                          max_bin = 358,\n",
    "                          subsample = 0.9974697184313627,\n",
    "                          learning_rate = 0.009464402227606937,\n",
    "                          max_depth = 11,\n",
    "                          min_data_in_leaf = 139,\n",
    "                          eval_metric = 'RMSE',\n",
    "                          iterations = 8694,\n",
    "                          task_type='GPU',\n",
    "                          bootstrap_type = 'Poisson',\n",
    "                          early_stopping_rounds = 100,\n",
    "                          verbose=500\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112a0a1-c925-4152-a311-ea9586180f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "k = 20 # a number of folds best is 20\n",
    "skfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=113)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import r2_score\n",
    "from catboost import Pool\n",
    "\n",
    "y_valid_pred = 0*y_train\n",
    "y_test_pred = 0\n",
    "\n",
    "FEATURE = ['User-ID','Book-Title','Book-Author','Publisher', 'City','State','Country','Age_gb']#, 'Rating_gb']# 'Pub_gb']\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(skfold.split(X_train, y_train))):    \n",
    "    X_train_fold, X_valid_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train_fold, y_valid_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_train_fold[FEATURE] = X_train_fold[FEATURE].astype('int')\n",
    "    X_valid_fold[FEATURE] = X_valid_fold[FEATURE].astype('int')\n",
    "    \n",
    "    train_pool = Pool(data=X_train_fold, label=y_train_fold, cat_features=FEATURE)\n",
    "    valid_pool = Pool(data=X_valid_fold, label=y_valid_fold, cat_features=FEATURE)\n",
    "\n",
    "    \n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    fit_model = model.fit(train_pool, \n",
    "                          eval_set=valid_pool,\n",
    "                          use_best_model=True\n",
    "                          )\n",
    "    print( \"  N trees = \", model.tree_count_ )\n",
    "        \n",
    "\n",
    "    def score_model(model,X_train, X_test, y_train, y_test,\n",
    "               show_plot=True):   \n",
    "        y_pred = np.clip(model.predict(X_test),0,10)\n",
    "        print(f\"Test score: {r2_score(y_test, y_pred)}\")\n",
    "        print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "        print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "        predictions_comparision = pd.DataFrame({'Actual': y_test.tolist(), 'Predicted': y_pred.tolist()}).sample(25)\n",
    "        if show_plot == True:\n",
    "            predictions_comparision.plot(kind=\"bar\", figsize=(12,8),title=\"Actual vs predicted values\")\n",
    "            print(predictions_comparision.sample(10))    \n",
    "    \n",
    "    \n",
    "        return {\n",
    "            \"test_score_r2\" : r2_score(y_test, y_pred),\n",
    "            \"test_score_mse\" : mean_squared_error(y_test, y_pred),\n",
    "            \"test_score_rmse\" : np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            }\n",
    "    score_model(fit_model, X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, show_plot=True)\n",
    "    \n",
    "    x_test[FEATURE] = x_test[FEATURE].astype('int')\n",
    "    # Predict value Clipping\n",
    "    y_test_pred +=  np.clip(fit_model.predict(x_test[X_valid_fold.columns]),0.0,10.0)\n",
    "    \n",
    "y_test_pred /= k  # Average test set predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef48dcb-c7a2-4e6d-93b0-7d60c8d9989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_importance_feature = np.argsort(model.feature_importances_)[:-31:-1]\n",
    "plt.barh(X_train.columns[cat_importance_feature], model.feature_importances_[cat_importance_feature])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b65b1-bd59-4f95-bdac-324cb42b9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['ID'] = test['ID']\n",
    "sub['Book-Rating'] = y_test_pred\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eda32e-6d8c-4f88-9174-ffe9219afc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(sub['Book-Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab828f-ebae-443d-a51a-4c44f48e3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submit_cat+20-folds+binary.csv', index=False,encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
